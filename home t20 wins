import pandas as pd
from urllib.request import urlopen
from bs4 import BeautifulSoup
#pip install BeautifulSoup
urllink = "https://stats.espncricinfo.com/ci/engine/stats/index.html?class=3;home_or_away=1;result=1;spanmax1=22+Dec+2020;spanmin1=30+Apr+2010;spanval1=span;template=results;type=team;view=results"
urllink
text = urlopen(urllink)
text
soup = BeautifulSoup(text,'lxml')
soup
list_tables = soup.findAll('table',attrs = {'class':'engineTable'})
len(list_tables)
list_tables[0]
int_table = 0
i=0
for table in list_tables:
    caption_tag = table.findAll('caption')
    print("for table number: " + str(i+1) + ",len of caption = " + str(len(caption_tag)))
    if(len(caption_tag) == 1):
        int_table = i
    i=i+1
    
    print(int_table)
    data_table = list_tables[int_table]
    data_table
    tr_list = data_table.findAll('tr', attrs = {'class':'data1'})
    len(tr_list)
    tr_list[0]
    temp_row = tr_list[0]
    td_list = temp_row.findAll('td')
    td_list[2]
    str_cells = str(td_list[3])
    str_cells
    cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
    cleantext
    td_data = []
for td in td_list:
    str_cells = str(td)
    cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
    td_data.append(cleantext)
    td_data
    master_data = []
for tr in tr_list:
    td_list = tr.findAll('td')
    td_data = []
    for td in td_list:
        str_cells = str(td)
        cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
        td_data.append(cleantext)
    master_data.append(td_data)
    master_data
    len(master_data)
    master_data = pd.DataFrame(master_data)
    master_data
    master_data = []
for j in range(1,7):
    urllink = "https://stats.espncricinfo.com/ci/engine/stats/index.html?class=3;home_or_away=1;page=" + str(j) + ";result=1;spanmax1=22+Dec+2020;spanmin1=30+Apr+2010;spanval1=span;template=results;type=team;view=results"
    text = urlopen(urllink)
    soup = BeautifulSoup(text, 'lxml')
    list_tables = soup.findAll('table', attrs = {'class':'engineTable'})
    int_table = 0
    i=0
    for table in list_tables:
        caption_tag = table.findAll('caption')
        print("for table number: " + str(i+1) + ", len of caption = " + str(len(caption_tag)))
        if(len(caption_tag) == 1):
            int_table = i
        i=i+1
    data_table = list_tables[int_table]
    tr_list = data_table.findAll('tr', attrs = {'class':'data1'})
    for tr in tr_list:
        td_list = tr.findAll('td')
        td_data = []
        for td in td_list:
            str_cells = str(td)
            cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
            td_data.append(cleantext)
        master_data.append(td_data)
        master_data
        len(master_data)
        master_data = pd.DataFrame(master_data)
        master_data
        df = master_data
        df
        df = df.drop(columns=[6,10])
        df
        df.columns = ["Country","Result","Margin of victory","Balls remaining","Toss Result","Batting","Opponent","Venue","Date"]
        df
        df.to_csv('C:/Users/Damle/Desktop/homet20wins.csv')
